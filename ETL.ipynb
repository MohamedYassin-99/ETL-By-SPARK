{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat_ws, year, month,to_date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType,DecimalType,FloatType,ShortType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.jars\",\"/home/bigdata/postgresql-42.6.0.jar\") \\\n",
    "   .master(\"local\").appName(\"ETL Pipeline by Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Csv Files data into PySpark DataFrame(Data Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calender = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Calendar.csv\")\n",
    "Customer = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Customers.csv\")\n",
    "Product_Categories = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Product_Categories.csv\")\n",
    "Product = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Products.csv\" )\n",
    "Product_Sub_Category = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Product_Subcategories.csv\" )\n",
    "Sales_2015 = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Sales_2015.csv\")\n",
    "Sales_2016 = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Sales_2016.csv\")\n",
    "Sales_2017 = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Sales_2017.csv\")\n",
    "Territories = spark.read.option(\"header\",\"true\").csv(\"/home/bigdata/ETL/Adventure_Works/AdventureWorks_Territories.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+--------+-------------+------+------------+---------------+--------------+\n",
      "|CustomerKey|FirstName|LastName|MaritalStatus|Gender|AnnualIncome| EducationLevel|    Occupation|\n",
      "+-----------+---------+--------+-------------+------+------------+---------------+--------------+\n",
      "|      11000|      JON|    YANG|            M|     M|    $90,000 |      Bachelors|  Professional|\n",
      "|      11001|   EUGENE|   HUANG|            S|     M|    $60,000 |      Bachelors|  Professional|\n",
      "|      11002|    RUBEN|  TORRES|            M|     M|    $60,000 |      Bachelors|  Professional|\n",
      "|      11003|  CHRISTY|     ZHU|            S|     F|    $70,000 |      Bachelors|  Professional|\n",
      "|      11004|ELIZABETH| JOHNSON|            S|     F|    $80,000 |      Bachelors|  Professional|\n",
      "|      11005|    JULIO|    RUIZ|            S|     M|    $70,000 |      Bachelors|  Professional|\n",
      "|      11007|    MARCO|   MEHTA|            M|     M|    $60,000 |      Bachelors|  Professional|\n",
      "|      11008|    ROBIN| VERHOFF|            S|     F|    $60,000 |      Bachelors|  Professional|\n",
      "|      11009|  SHANNON| CARLSON|            S|     M|    $70,000 |      Bachelors|  Professional|\n",
      "|      11010|JACQUELYN|  SUAREZ|            S|     F|    $70,000 |      Bachelors|  Professional|\n",
      "|      11011|   CURTIS|      LU|            M|     M|    $60,000 |      Bachelors|  Professional|\n",
      "|      11012|   LAUREN|  WALKER|            M|     F|   $100,000 |      Bachelors|    Management|\n",
      "|      11013|      IAN| JENKINS|            M|     M|   $100,000 |      Bachelors|    Management|\n",
      "|      11014|   SYDNEY| BENNETT|            S|     F|   $100,000 |      Bachelors|    Management|\n",
      "|      11015|    CHLOE|   YOUNG|            S|     F|    $30,000 |Partial College|Skilled Manual|\n",
      "|      11016|    WYATT|    HILL|            M|     M|    $30,000 |Partial College|Skilled Manual|\n",
      "|      11017|  SHANNON|    WANG|            S|     F|    $20,000 |    High School|Skilled Manual|\n",
      "|      11018| CLARENCE|     RAI|            S|     M|    $30,000 |Partial College|      Clerical|\n",
      "|      11019|     LUKE|     LAL|            S|     M|    $40,000 |    High School|Skilled Manual|\n",
      "|      11020|   JORDAN|    KING|            S|     M|    $40,000 |    High School|Skilled Manual|\n",
      "+-----------+---------+--------+-------------+------+------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- CustomerKey: integer (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- AnnualIncome: string (nullable = true)\n",
      " |-- EducationLevel: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Customer Table\n",
    "Customer.createOrReplaceTempView(\"Customer_Dim\")\n",
    "query = \"SELECT INT(CustomerKey),FirstName,LastName,MaritalStatus,Gender,AnnualIncome,EducationLevel,Occupation  from Customer_Dim ;\"\n",
    "Customer_Dim = spark.sql(query)\n",
    "Customer_Dim.show()\n",
    "Customer_Dim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------------+---------------+\n",
      "|ProductId|ProductName|Product_Cat_Name|Product_Sub_Cat|\n",
      "+---------+-----------+----------------+---------------+\n",
      "|      310|   Road-150|      Components|     Road Bikes|\n",
      "|      311|   Road-150|      Components|     Road Bikes|\n",
      "|      312|   Road-150|      Components|     Road Bikes|\n",
      "|      313|   Road-150|      Components|     Road Bikes|\n",
      "|      314|   Road-150|      Components|     Road Bikes|\n",
      "|      315|   Road-450|      Components|     Road Bikes|\n",
      "|      316|   Road-450|      Components|     Road Bikes|\n",
      "|      317|   Road-450|      Components|     Road Bikes|\n",
      "|      318|   Road-450|      Components|     Road Bikes|\n",
      "|      319|   Road-450|      Components|     Road Bikes|\n",
      "|      320|   Road-650|      Components|     Road Bikes|\n",
      "|      322|   Road-650|      Components|     Road Bikes|\n",
      "|      324|   Road-650|      Components|     Road Bikes|\n",
      "|      326|   Road-650|      Components|     Road Bikes|\n",
      "|      328|   Road-650|      Components|     Road Bikes|\n",
      "|      330|   Road-650|      Components|     Road Bikes|\n",
      "|      332|   Road-650|      Components|     Road Bikes|\n",
      "|      334|   Road-650|      Components|     Road Bikes|\n",
      "|      336|   Road-650|      Components|     Road Bikes|\n",
      "|      338|   Road-650|      Components|     Road Bikes|\n",
      "+---------+-----------+----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- ProductId: integer (nullable = true)\n",
      " |-- ProductName: string (nullable = true)\n",
      " |-- Product_Cat_Name: string (nullable = true)\n",
      " |-- Product_Sub_Cat: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Product Table\n",
    "Product_Categories.createOrReplaceTempView(\"ProductCateg\")\n",
    "Product.createOrReplaceTempView(\"Product\")\n",
    "Product_Sub_Category.createOrReplaceTempView(\"ProductSub\")\n",
    "query_prod = \" Select INT(P.ProductKey) as ProductId , P.ModelName as ProductName ,PC.CategoryName as Product_Cat_Name ,PSC.SubcategoryName as Product_Sub_Cat from Product P  inner join ProductSub PSC on P.ProductSubcategoryKey = PSC.ProductSubcategoryKey inner join ProductCateg PC on PSC.ProductSubcategoryKey = PC.ProductCategoryKey  ;\"\n",
    "Product_Dim = spark.sql(query_prod)\n",
    "Product_Dim.show()\n",
    "Product_Dim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------+-----+---+\n",
      "|DateKey|year| Quarter|Month|Day|\n",
      "+-------+----+--------+-----+---+\n",
      "| 201511|2015|Quarter1|    1|  1|\n",
      "| 201512|2015|Quarter1|    1|  2|\n",
      "| 201513|2015|Quarter1|    1|  3|\n",
      "| 201514|2015|Quarter1|    1|  4|\n",
      "| 201515|2015|Quarter1|    1|  5|\n",
      "| 201516|2015|Quarter1|    1|  6|\n",
      "| 201517|2015|Quarter1|    1|  7|\n",
      "| 201518|2015|Quarter1|    1|  8|\n",
      "| 201519|2015|Quarter1|    1|  9|\n",
      "|2015110|2015|Quarter1|    1| 10|\n",
      "|2015111|2015|Quarter1|    1| 11|\n",
      "|2015112|2015|Quarter1|    1| 12|\n",
      "|2015113|2015|Quarter1|    1| 13|\n",
      "|2015114|2015|Quarter1|    1| 14|\n",
      "|2015115|2015|Quarter1|    1| 15|\n",
      "|2015116|2015|Quarter1|    1| 16|\n",
      "|2015117|2015|Quarter1|    1| 17|\n",
      "|2015118|2015|Quarter1|    1| 18|\n",
      "|2015119|2015|Quarter1|    1| 19|\n",
      "|2015120|2015|Quarter1|    1| 20|\n",
      "+-------+----+--------+-----+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- DateKey: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- Quarter: string (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Date Table\n",
    "Calender.createOrReplaceTempView(\"Date_Dim\")\n",
    "date_query =\"Select Date_Format(to_date(regexp_replace(Date,'/','-'),'M-d-yyyy'),'yyyyMd') as DateKey ,year(to_date(regexp_replace(Date,'/','-'),'M-d-yyyy')) as year , concat('Quarter',quarter(to_date(regexp_replace(Date,'/','-'),'M-d-yyyy'))) as Quarter , month(to_date(regexp_replace(Date,'/','-'),'M-d-yyyy')) as Month , day(to_date(regexp_replace(Date,'/','-'),'M-d-yyyy')) as Day from Date_Dim ; \"\n",
    "Date_Dim = spark.sql(date_query)\n",
    "Date_Dim.show()\n",
    "Date_Dim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+--------------+-------------+\n",
      "|SalesTerritoryKey|        Region|       Country|    Continent|\n",
      "+-----------------+--------------+--------------+-------------+\n",
      "|                1|     Northwest| United States|North America|\n",
      "|                2|     Northeast| United States|North America|\n",
      "|                3|       Central| United States|North America|\n",
      "|                4|     Southwest| United States|North America|\n",
      "|                5|     Southeast| United States|North America|\n",
      "|                6|        Canada|        Canada|North America|\n",
      "|                7|        France|        France|       Europe|\n",
      "|                8|       Germany|       Germany|       Europe|\n",
      "|                9|     Australia|     Australia|      Pacific|\n",
      "|               10|United Kingdom|United Kingdom|       Europe|\n",
      "+-----------------+--------------+--------------+-------------+\n",
      "\n",
      "root\n",
      " |-- SalesTerritoryKey: integer (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Territory Table\n",
    "Territories.createOrReplaceTempView(\"Territory_Dim\")\n",
    "Query =\"Select INT(SalesTerritoryKey),Region,Country,Continent FROM Territory_Dim ; \" \n",
    "Territory_Dim = spark.sql(Query) \n",
    "Territory_Dim.show()\n",
    "Territory_Dim.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------+--------+------------+-------------+-----------+------------+\n",
      "|OrderNumber|CustomerKey|ProductKey| DateKey|TerritoryKey|OrderQuantity|ProdcutCost|ProductPrice|\n",
      "+-----------+-----------+----------+--------+------------+-------------+-----------+------------+\n",
      "|    SO45164|      11453|       349| 2015115|           9|            1|  1898.0944|     3374.99|\n",
      "|    SO45240|      29155|       310| 2015128|           1|            1|  2171.2942|     3578.27|\n",
      "|    SO45466|      19611|       311| 2015221|           9|            1|  2171.2942|     3578.27|\n",
      "|    SO45641|      23306|       311| 2015310|           6|            1|  2171.2942|     3578.27|\n",
      "|    SO45946|      11914|       350| 2015420|           9|            1|  1898.0944|     3374.99|\n",
      "|    SO46453|      20626|       313| 2015610|           9|            1|  2171.2942|     3578.27|\n",
      "|    SO46677|      15460|       371|  201571|           8|            1|  1320.6838|   2181.5625|\n",
      "|    SO47094|      15664|       377|  201584|           8|            1|  1320.6838|   2181.5625|\n",
      "|    SO47188|      19253|       389| 2015815|          10|            1|   605.6492|   1000.4375|\n",
      "|    SO47258|      13298|       377| 2015822|           4|            1|  1320.6838|   2181.5625|\n",
      "|    SO47470|      28685|       358|  201593|           7|            1|    1105.81|   2049.0982|\n",
      "|    SO47585|      15320|       328| 2015919|           1|            1|   413.1463|    699.0982|\n",
      "|    SO47582|      13433|       373| 2015919|           4|            1|  1320.6838|   2181.5625|\n",
      "|    SO47637|      13447|       371| 2015927|           4|            1|  1320.6838|   2181.5625|\n",
      "|    SO47831|      12281|       362|20151015|          10|            1|    1105.81|   2049.0982|\n",
      "|    SO48415|      26634|       356| 2015122|           4|            1|  1117.8559|   2071.4196|\n",
      "|    SO48949|      26591|       334| 2016119|           9|            1|   413.1463|    699.0982|\n",
      "|    SO49318|      27267|       332| 2016215|           6|            1|   413.1463|    699.0982|\n",
      "|    SO49437|      19336|       330| 2016228|           7|            1|   413.1463|    699.0982|\n",
      "|    SO49681|      13890|       379| 2016315|           1|            1|  1320.6838|   2181.5625|\n",
      "+-----------+-----------+----------+--------+------------+-------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- OrderNumber: string (nullable = true)\n",
      " |-- CustomerKey: integer (nullable = true)\n",
      " |-- ProductKey: integer (nullable = true)\n",
      " |-- DateKey: string (nullable = true)\n",
      " |-- TerritoryKey: integer (nullable = true)\n",
      " |-- OrderQuantity: string (nullable = true)\n",
      " |-- ProdcutCost: string (nullable = true)\n",
      " |-- ProductPrice: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sales Fact Table\n",
    "Sales_2015.createOrReplaceTempView(\"Sales_2015\")\n",
    "Sales_2016.createOrReplaceTempView(\"Sales_2016\")\n",
    "Sales_2017.createOrReplaceTempView(\"Sales_2017\")\n",
    "Product.createOrReplaceTempView(\"Product\")\n",
    "Query =\"Select OrderNumber,INT(CustomerKey),INT(S15.ProductKey),Date_Format(to_date(regexp_replace(OrderDate,'/','-'),'M-d-yyyy'),'yyyyMd') as DateKey,INT(TerritoryKey),OrderQuantity,P.ProductCost as ProdcutCost,P.ProductPrice as ProductPrice FROM Sales_2015 S15 inner join Product P on S15.ProductKey = P.ProductKey union select OrderNumber,INT(CustomerKey),INT(S16.ProductKey),Date_Format(to_date(regexp_replace(OrderDate,'/','-'),'M-d-yyyy'),'yyyyMd') as DateKey,INT(TerritoryKey),OrderQuantity,P.ProductCost as ProdcutCost,P.ProductPrice as ProductPrice FROM Sales_2016 S16 inner join Product P on S16.ProductKey = P.ProductKey  union select OrderNumber,INT(CustomerKey),INT(S17.ProductKey),Date_Format(to_date(regexp_replace(OrderDate,'/','-'),'M-d-yyyy'),'yyyyMd') as DateKey,INT(TerritoryKey),OrderQuantity,P.ProductCost as ProdcutCost,P.ProductPrice as ProductPrice FROM Sales_2017 S17 inner join Product P on S17.ProductKey = P.ProductKey  ; \" \n",
    "Sales_Fact = spark.sql(Query) \n",
    "Sales_Fact.show()\n",
    "Sales_Fact.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Dim.write.format('csv').option('header',True).mode('overwrite').option('sep',',').save('/home/bigdata/ETL/Output/Customer_Dim.csv')\n",
    "Product_Dim.write.format('csv').option('header',True).mode('overwrite').option('sep',',').save('/home/bigdata/ETL/Output/Product_Dim.csv')\n",
    "Territory_Dim.write.format('csv').option('header',True).mode('overwrite').option('sep',',').save('/home/bigdata/ETL/Output/Territory_Dim.csv')\n",
    "Date_Dim.write.format('csv').option('header',True).mode('overwrite').option('sep',',').save('/home/bigdata/ETL/Output/Date_Dim.csv')\n",
    "Sales_Fact.write.format('csv').option('header',True).mode('overwrite').option('sep',',').save('/home/bigdata/ETL/Output/Sales_Fact.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
